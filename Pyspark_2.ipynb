{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj3jUNvLY/Htw2urzF58no",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-abs/Apache-Spark/blob/main/Pyspark_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Schema Creation"
      ],
      "metadata": {
        "id": "JdmEPNgBAHxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "DH2-2LgxuXB0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructField,StructType,StringType,IntegerType"
      ],
      "metadata": {
        "id": "dT6G8cId-LbI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schema in Pyspark 2 ways-\n",
        "\n",
        "1.DDL\n",
        "\n",
        "2.StructType/StructField"
      ],
      "metadata": {
        "id": "FUYbfGvV_OUy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-PkjwhGt2N0",
        "outputId": "956efbf4-3109-4af3-c945-538de18ce4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+-----+\n",
            "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
            "+--------------------+-------------------+-----+\n",
            "|       United States|            Romania|    1|\n",
            "|       United States|            Ireland|  264|\n",
            "|       United States|              India|   69|\n",
            "|               Egypt|      United States|   24|\n",
            "|   Equatorial Guinea|      United States|    1|\n",
            "|       United States|          Singapore|   25|\n",
            "|       United States|            Grenada|   54|\n",
            "|          Costa Rica|      United States|  477|\n",
            "|             Senegal|      United States|   29|\n",
            "|       United States|   Marshall Islands|   44|\n",
            "|              Guyana|      United States|   17|\n",
            "|       United States|       Sint Maarten|   53|\n",
            "|               Malta|      United States|    1|\n",
            "|             Bolivia|      United States|   46|\n",
            "|            Anguilla|      United States|   21|\n",
            "|Turks and Caicos ...|      United States|  136|\n",
            "|       United States|        Afghanistan|    2|\n",
            "|Saint Vincent and...|      United States|    1|\n",
            "|               Italy|      United States|  390|\n",
            "|       United States|             Russia|  156|\n",
            "+--------------------+-------------------+-----+\n",
            "only showing top 20 rows\n",
            "root\n",
            " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
            " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
            " |-- count: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Read CSV Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Read CSV file\n",
        "df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(my_schema) \\\n",
        "    .load(\"/content/2010-summary.csv\")\n",
        "\n",
        "\n",
        "# Show data\n",
        "df.show()\n",
        "\n",
        "# Check schema\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_schema=StructType([\n",
        "    StructField(\"DEST_COUNTRY_NAME\",StringType(),True),\n",
        "    StructField(\"ORIGIN_COUNTRY_NAME\",StringType(),True),\n",
        "    StructField(\"count\",IntegerType(),True)\n",
        "])"
      ],
      "metadata": {
        "id": "CW0jm2xFvO7N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yjw9NDXW_k2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}